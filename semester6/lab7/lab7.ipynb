{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "hsbyb4tyki9nx32utdtjpk",
    "id": "71AQJg3CDMn9"
   },
   "source": [
    "# Deep learning для классификации картинок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Семинар состоит из 2 частей\n",
    "\n",
    "1. Ознакомьтесь со структурой обычного обучающего скрипта и потренируйте старую добрую сеть, подобную vgg\n",
    "2. Улучшите качество с помощью сети, подобной resnet\n",
    "\n",
    "Но сначала посмотрим на данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./vgg-neural-network-architecture.png\" alt=\"Drawing\" style=\"width:90%\"/> </td>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "34l2kkk7t84llsmzyxus1",
    "id": "2MaELIpIDMoA"
   },
   "source": [
    "# Tiny ImageNet dataset\n",
    "На этом семинаре мы сосредоточимся на задаче распознавания изображений на Tiny Image Net dataset. Этот набор данных содержит\n",
    "* 100 тысяч изображений размером 3x64x64\n",
    "* 200 различных классов: змеи, пауки, кошки, грузовики, кузнечики, чайки и т.д.\n",
    "\n",
    "На самом деле, это подмножество набора данных ImageNet с изображениями, уменьшенными в 4 раза."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "rjwf5t0s4f8zbnfmyu7q",
    "id": "swKtJaVyDMoU"
   },
   "source": [
    "## Image examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "nbxuu26h8hhcgzzgeh5nh",
    "id": "h5wImXEaDMoV"
   },
   "source": [
    "\n",
    "\n",
    "<tr>\n",
    "    <td> <img src=\"https://github.com/yandexdataschool/Practical_DL/blob/sem3spring2019/week03_convnets/tinyim3.png?raw=1\" alt=\"Drawing\" style=\"width:90%\"/> </td>\n",
    "    <td> <img src=\"https://github.com/yandexdataschool/Practical_DL/blob/sem3spring2019/week03_convnets/tinyim2.png?raw=1\" alt=\"Drawing\" style=\"width:90%\"/> </td>\n",
    "</tr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "w71ngep3y8jm2s3xt0qg",
    "id": "Do-qRQp8DMoW"
   },
   "source": [
    "<tr>\n",
    "    <td> <img src=\"https://github.com/yandexdataschool/Practical_DL/blob/sem3spring2019/week03_convnets/tiniim.png?raw=1\" alt=\"Drawing\" style=\"width:90%\"/> </td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0 - data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:15.634264Z",
     "iopub.status.busy": "2025-06-02T00:05:15.633932Z",
     "iopub.status.idle": "2025-06-02T00:05:15.642719Z",
     "shell.execute_reply": "2025-06-02T00:05:15.642199Z",
     "shell.execute_reply.started": "2025-06-02T00:05:15.634230Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    from urllib import urlretrieve\n",
    "else:\n",
    "    from urllib.request import urlretrieve\n",
    "\n",
    "\n",
    "def download_tinyImg200(path,\n",
    "                        url='http://cs231n.stanford.edu/tiny-imagenet-200.zip',\n",
    "                        tarname='tiny-imagenet-200.zip'):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "\n",
    "    output_name = os.path.join(path, tarname)\n",
    "    if os.path.exists(output_name):\n",
    "        print(\"Dataset was already downloaded to '{}'. Skip downloading\".format(output_name))\n",
    "    else:\n",
    "        urlretrieve(url, output_name)\n",
    "        print(\"Dataset was downloaded to '{}'\".format(output_name))\n",
    "\n",
    "    print(\"Extract downloaded dataset to '{}'\".format(path))\n",
    "    with zipfile.ZipFile(output_name, 'r') as f:\n",
    "        f.extractall(path=path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellId": "5nh892g5zpl9qv5fki8vpk",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:15.644070Z",
     "iopub.status.busy": "2025-06-02T00:05:15.643821Z",
     "iopub.status.idle": "2025-06-02T00:05:34.361730Z",
     "shell.execute_reply": "2025-06-02T00:05:34.361141Z",
     "shell.execute_reply.started": "2025-06-02T00:05:15.644055Z"
    },
    "id": "5rQhiYyRDMoG",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset was downloaded to '/kaggle/working/tiny-imagenet-200.zip'\n",
      "Extract downloaded dataset to '/kaggle/working/'\n"
     ]
    }
   ],
   "source": [
    "data_path = '/kaggle/working/'\n",
    "download_tinyImg200(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Training script structure and vgg-like network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы обучить нейронную сеть, надо решить 5 задач:\n",
    "1. data loader (data provider) - как загружать и дополнять данные для обучения nn\n",
    "2. neural network architecture - что будет обучаться\n",
    "3. loss function (+ auxilary metrics on train and validation set) - как проверить качество нейронной сети\n",
    "4. optiimzer and training schedule - как будет обучаться нейронная сеть\n",
    "5. \"Train loop\" - что именно нужно делать для каждого пакета, как часто проверять ошибку проверки, как часто сохранять сеть и т.д. Этот код можно было бы написать в общем виде и повторно использовать в разных сценариях обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellId": "g2i37mixtk9kkxkki1y8",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:34.362540Z",
     "iopub.status.busy": "2025-06-02T00:05:34.362361Z",
     "iopub.status.idle": "2025-06-02T00:05:39.600453Z",
     "shell.execute_reply": "2025-06-02T00:05:39.599826Z",
     "shell.execute_reply.started": "2025-06-02T00:05:34.362524Z"
    },
    "id": "rS_-00tYDMoB",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our main computing device is 'cuda:0'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import tqdm\n",
    "\n",
    "def get_computing_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda:0')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    return device\n",
    "\n",
    "device = get_computing_device()\n",
    "print(f\"Our main computing device is '{device}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Data loader and data augmentation\n",
    "Обычно для манипулирования данными используются две связанные абстракции:\n",
    "- Dataset (`torch.utils.data.Dataset` и его подклассы из `torchvision.datasets\") - некоторый черный ящик, который хранит и предварительно обрабатывает отдельные элементы dataset. В частности, на этом уровне обычно находятся дополнения для отдельных образцов.\n",
    "- DataLoader (`torch.utils.data.DataLoader`) - структура, объединяющая отдельные элементы в пакетном режиме.\n",
    "\n",
    "Давайте разберемся с обучающим набором данных. Вот несколько простых дополнений, которые мы собираемся использовать в наших экспериментах:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:39.602128Z",
     "iopub.status.busy": "2025-06-02T00:05:39.601845Z",
     "iopub.status.idle": "2025-06-02T00:05:39.606320Z",
     "shell.execute_reply": "2025-06-02T00:05:39.605602Z",
     "shell.execute_reply.started": "2025-06-02T00:05:39.602110Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_trainsforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.ColorJitter(0.5, 0.5, 0.5),\n",
    "    transforms.RandomGrayscale(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для набора обучающих данных мы будем использовать пользовательский набор данных, который будет хранить все обучающие данные в оперативной памяти. Если у вас недостаточно оперативной памяти, вы можете использовать `torch vision.datasets.ImageFolder()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellId": "jrzsbgniodgtg1hif324k9",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:39.607591Z",
     "iopub.status.busy": "2025-06-02T00:05:39.607113Z",
     "iopub.status.idle": "2025-06-02T00:05:39.826802Z",
     "shell.execute_reply": "2025-06-02T00:05:39.826082Z",
     "shell.execute_reply.started": "2025-06-02T00:05:39.607572Z"
    },
    "id": "5vq5Cm0ADMoK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# you may use torchvision.datasets.ImageFolder() with the same parameters for loading train dataset \n",
    "train_dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/train', transform=train_trainsforms)\n",
    "# train_dataset = tiny_img_dataset.TinyImagenetRAM('tiny-imagenet-200/train', transform=train_trainsforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь проверка. Взгляните на папку `tiny-imagenet-200/val` и сравните ее с папкой `tiny-imagenet-200/train`. Выглядит по-другому, не так ли? Таким образом, мы не можем использовать `TinyImagenetRAM` для загрузки набора данных для проверки. Давайте вместо этого напишем пользовательский набор данных, но с таким же поведением, как у `TinyImagenetRAM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:39.827890Z",
     "iopub.status.busy": "2025-06-02T00:05:39.827623Z",
     "iopub.status.idle": "2025-06-02T00:05:40.119618Z",
     "shell.execute_reply": "2025-06-02T00:05:40.118959Z",
     "shell.execute_reply.started": "2025-06-02T00:05:39.827858Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class TinyImagenetValDataset(Dataset):\n",
    "    def __init__(self, root, transform=transforms.ToTensor()):\n",
    "        super().__init__()\n",
    "\n",
    "        self.root = root\n",
    "        with open(os.path.join(root, 'val_annotations.txt')) as f:\n",
    "            annotations = []\n",
    "            for line in f:\n",
    "                img_name, class_label = line.split('\\t')[:2]\n",
    "                annotations.append((img_name, class_label))\n",
    "\n",
    "        # 1. define self.classes - list of sorted class labels from annotations\n",
    "        # it should look like self.classes from \"TinyImagenetRAM\"\n",
    "        # YOUR CODE\n",
    "        self.classes = sorted(list(set([label for _, label in annotations])))\n",
    "        \n",
    "        assert len(self.classes) == 200, len(self.classes)\n",
    "        assert all(self.classes[i] < self.classes[i+1] for i in range(len(self.classes)-1)), 'classes should be ordered'\n",
    "        assert all(isinstance(elem, type(annotations[0][1])) for elem in self.classes), 'your just need to reuse class_labels'\n",
    "\n",
    "        # 2. self.class_to_idx - dict from class label to class index\n",
    "        self.class_to_idx = {item: index for index, item in enumerate(self.classes)}\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        self.images, self.targets = [], []\n",
    "        for img_name, class_name in tqdm.tqdm(annotations, desc=root):\n",
    "            img_name = os.path.join(root, 'images', img_name)\n",
    "            # 3. load image and store it in self.images (your may want to use tiny_img_dataset.read_rgb_image)\n",
    "            # store the class index in self.targets\n",
    "            # YOUR CODE\n",
    "            image = self.read_rgb_image(img_name)\n",
    "            \n",
    "            assert image.shape == (64, 64, 3), image.shape\n",
    "            self.images.append(Image.fromarray(image))\n",
    "            self.targets.append(self.class_to_idx[class_name])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # take image and its target label from \"self.images\" and \"self.targets\", \n",
    "        # transform the image using self.transform and return the transformed image and its target label\n",
    "        \n",
    "        # YOUR CODE\n",
    "        image = self.images[index]\n",
    "        image = self.transform(image)\n",
    "        target = self.targets[index]\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    @staticmethod\n",
    "    def read_rgb_image(path_to_image):\n",
    "        image = cv2.imread(path_to_image)\n",
    "        return  cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # np.array(img.convert(\"RGB\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте, наконец, загрузим набор данных для проверки. Обычно вам не применять аугментации для проверки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:40.120698Z",
     "iopub.status.busy": "2025-06-02T00:05:40.120394Z",
     "iopub.status.idle": "2025-06-02T00:05:41.302163Z",
     "shell.execute_reply": "2025-06-02T00:05:41.301494Z",
     "shell.execute_reply.started": "2025-06-02T00:05:40.120678Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tiny-imagenet-200/val: 100%|██████████| 10000/10000 [00:01<00:00, 8589.51it/s]\n"
     ]
    }
   ],
   "source": [
    "val_dataset = TinyImagenetValDataset('tiny-imagenet-200/val', transform=transforms.ToTensor())\n",
    "\n",
    "assert all(train_dataset.classes[i] == val_dataset.classes[i] for i in range(200)), \\\n",
    "    'class order in train and val datasets should be the same'\n",
    "assert all(train_dataset.class_to_idx[elem] == val_dataset.class_to_idx[elem] for elem in train_dataset.classes), \\\n",
    "    'class indices should be the same'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для большинства случаев будет достаточно `DataLoader` по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellId": "6md8io0fesfby4r9per3jb",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:41.303319Z",
     "iopub.status.busy": "2025-06-02T00:05:41.302957Z",
     "iopub.status.idle": "2025-06-02T00:05:41.307289Z",
     "shell.execute_reply": "2025-06-02T00:05:41.306651Z",
     "shell.execute_reply.started": "2025-06-02T00:05:41.303277Z"
    },
    "id": "tY6OUeOODMoN",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_batch_gen = torch.utils.data.DataLoader(train_dataset, \n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellId": "hsq566ut87vokpkiq68",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:41.308111Z",
     "iopub.status.busy": "2025-06-02T00:05:41.307946Z",
     "iopub.status.idle": "2025-06-02T00:05:41.321707Z",
     "shell.execute_reply": "2025-06-02T00:05:41.321190Z",
     "shell.execute_reply.started": "2025-06-02T00:05:41.308098Z"
    },
    "id": "HBgW-gzwDMoQ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_batch_gen = torch.utils.data.DataLoader(val_dataset, \n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False,\n",
    "                                            num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "fxzxgbl11g2dixss4t9nx",
    "id": "arxSyhBLDMoX"
   },
   "source": [
    "### 1.2 Определение нейронной сети\n",
    "\n",
    "\"Сеть, подобная VGG\", обычно означает, что сеть представляет собой последовательность сверток с MaxPooling для понижающей размерности. Вот таблица из оригинальной статьи [\"Very Deep Convolutional Networks for Large-Scale Image Recognition\"].(https://arxiv.org/abs/1409.1556), который описывает классические конфигурации сетей VGG (часто называемые VGG-A, VGG-B и т.д. С использованием имени столбца в качестве идентификатора или VGG16, VGG19 и т.д. с использованием количества слоев в качестве идентификатора).\n",
    "\n",
    "![image.png](https://pytorch.org/assets/images/vgg.png)\n",
    "\n",
    "Эти сетевые конфигурации были разработаны для набора данных ImageNet. Поскольку изображения в tiny-imagenet имеют пониженный размер в 4 раза, мы собираемся разработать нашу собственную конфигурацию, уменьшив: \n",
    "1) количество слоев;\n",
    "2) количество нейронов в слоях;\n",
    "3) количество слоев с максимальным объединением, которые уменьшают выборку карт объектов\n",
    "\n",
    "Конфигурация нашей сети будет выглядеть следующим образом [Conv(16), Conv(16), MaxPool] + [Conv(32), Conv(32), MaxPool] + [Conv(64), Conv(64), MaxPool] + [Conv(128), Conv(128)] + [GlobalAveragePooling] + [FC(200) + softmax]\n",
    "\n",
    "\n",
    "Мы используем Conv(128) и GlobalAveragePooling вместо image flattening и слоев FC для уменьшения количества параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellId": "g5yf9z66xdpvq688ze2d8",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:41.324072Z",
     "iopub.status.busy": "2025-06-02T00:05:41.323641Z",
     "iopub.status.idle": "2025-06-02T00:05:41.336681Z",
     "shell.execute_reply": "2025-06-02T00:05:41.335867Z",
     "shell.execute_reply.started": "2025-06-02T00:05:41.324054Z"
    },
    "id": "7QF2hMVxDMoY",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "6yn15hpuolcmryork2oqs",
    "id": "DJ6QKG3hDMoa"
   },
   "source": [
    "И еще кое-что. VGG был разработан до того, как был придуман BatchNormalization. В настоящее время было бы глупо, если бы мы не использовали BatchNormalization в нашей сети. Итак, давайте определим простой модуль, содержащий свертку, BatchNormalization и relu, и построим нашу сеть, используя этот модуль. Вот также реализация GlobalAveragePooling, приведенная для вас в качестве примера пользовательского модуля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellId": "f985tf2dvssqwmyc6w99d",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:41.337494Z",
     "iopub.status.busy": "2025-06-02T00:05:41.337294Z",
     "iopub.status.idle": "2025-06-02T00:05:41.346745Z",
     "shell.execute_reply": "2025-06-02T00:05:41.346011Z",
     "shell.execute_reply.started": "2025-06-02T00:05:41.337481Z"
    },
    "id": "u_mbfRXMDMob",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#!L\n",
    "class GlobalAveragePool(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    def forward(self, x):\n",
    "        return torch.mean(x, dim=self.dim)\n",
    "\n",
    "    \n",
    "class ConvBNRelu(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding='same'):\n",
    "        super().__init__()\n",
    "        \n",
    "        # YOUR CODE: define vars for convolution, batchnorm, relu\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # YOUR CODE: sequentially apply convolution, batchnorm, relu to 'x'\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "def create_vgg_like_network(config=None):\n",
    "    \"\"\"\n",
    "    Creates VGG like network according to config\n",
    "    \"\"\"\n",
    "    model = nn.Sequential()\n",
    "    \n",
    "    default_config = [[16,16], [32, 32], [64, 64], [128, 128]]\n",
    "    config = config or default_config\n",
    "    \n",
    "    in_channels = 3\n",
    "    for block_index in range(len(config)):\n",
    "        for layer_index_in_block in range(len(config[block_index])):\n",
    "            out_channels = config[block_index][layer_index_in_block]\n",
    "            \n",
    "            # YOUR CODE: add ConvBNRelu module to model\n",
    "            model.add_module(f\"conv_{block_index}_{layer_index_in_block}\", ConvBNRelu(in_channels, out_channels, 3))\n",
    "            \n",
    "            in_channels = out_channels\n",
    "            \n",
    "        if block_index != len(config) - 1:\n",
    "            model.add_module(f'mp_{block_index}', nn.MaxPool2d(3, stride=2))\n",
    "            \n",
    "    model.add_module('pool', GlobalAveragePool(dim=(2,3)))\n",
    "    model.add_module('logits', nn.Linear(out_channels, 200))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот и создана наша модель!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:41.347622Z",
     "iopub.status.busy": "2025-06-02T00:05:41.347434Z",
     "iopub.status.idle": "2025-06-02T00:05:41.567122Z",
     "shell.execute_reply": "2025-06-02T00:05:41.566573Z",
     "shell.execute_reply.started": "2025-06-02T00:05:41.347608Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = create_vgg_like_network()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7dh3d8xmkeinv4kx0g079",
    "id": "DvugZZbeDMoe"
   },
   "source": [
    "### 1.3 Определение функции потерь\n",
    "\n",
    "Обычно в качестве функции потерь для классификации изображений используется cross-entropy (отрицательное логарифмическое правдоподобие)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellId": "3y7p7o6s7vecpf3kpktj8v",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:41.568107Z",
     "iopub.status.busy": "2025-06-02T00:05:41.567854Z",
     "iopub.status.idle": "2025-06-02T00:05:41.571668Z",
     "shell.execute_reply": "2025-06-02T00:05:41.571015Z",
     "shell.execute_reply.started": "2025-06-02T00:05:41.568081Z"
    },
    "id": "cGEhRWMYDMof",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(predictions, gt):\n",
    "    return F.cross_entropy(predictions, gt).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Optimizer and training schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обучим нашу сеть, используя Adam с параметрами по умолчанию. \n",
    "\n",
    "Для обучения с помощью `torch.optim.SGD` вам обычно нужно определить training schedule - способ, как снизить learning rate во время тренировки. Но поскольку в adam все градиенты масштабируются по моменту, эффект от правильного графика тренировок не так важен для обучения, как в SGD. Поэтому мы будем действовать как ленивые специалисты по обработке данных и не будем использовать шедулер вообще. Но вы можете поиграть с шедулером, используя, например, `torch.optim.lr_scheduler.ExponentialLR`, смотрите [документацию](https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate) с объяснением, как это использовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:41.572611Z",
     "iopub.status.busy": "2025-06-02T00:05:41.572393Z",
     "iopub.status.idle": "2025-06-02T00:05:41.586291Z",
     "shell.execute_reply": "2025-06-02T00:05:41.585632Z",
     "shell.execute_reply.started": "2025-06-02T00:05:41.572589Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Цикл обучения\n",
    "\n",
    "Давайте объединим ранее определенные элементы вместе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cellId": "w8rht9ygh7uns89ypozln",
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:48.894261Z",
     "iopub.status.busy": "2025-06-02T00:05:48.893988Z",
     "iopub.status.idle": "2025-06-02T00:05:48.901558Z",
     "shell.execute_reply": "2025-06-02T00:05:48.901007Z",
     "shell.execute_reply.started": "2025-06-02T00:05:48.894240Z"
    },
    "id": "sEy0LiHxDMol",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def eval_model(model, data_generator):\n",
    "    accuracy = []\n",
    "    model.train(False) # disable dropout / use averages for batch_norm\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_generator:\n",
    "            X_batch = X_batch.to(device)\n",
    "            logits = model(X_batch)\n",
    "            y_pred = logits.max(1)[1].data\n",
    "            accuracy.append(np.mean((y_batch.cpu() == y_pred.cpu()).numpy()))\n",
    "    return np.mean(accuracy)\n",
    "\n",
    "            \n",
    "def train_model(model, optimizer, train_data_generator):\n",
    "    train_loss = []\n",
    "    model.train(True) # enable dropout / batch_norm training behavior\n",
    "    for (X_batch, y_batch) in tqdm.tqdm(train_data_generator):\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # forward\n",
    "        # YOUR CODE: move X_batch, y_batch to 'device', compute model outputs on X_batch, \n",
    "        # run `compute_loss()` function\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        predictions = model(X_batch)\n",
    "        loss = compute_loss(predictions, y_batch)\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # metrics\n",
    "        train_loss.append(loss.cpu().data.numpy())\n",
    "    return np.mean(train_loss)\n",
    "\n",
    "\n",
    "def train_loop(model, optimizer, train_data_generator, val_data_generator, num_epochs):\n",
    "    \"\"\"\n",
    "    num_epochs - total amount of full passes over training data\n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        train_loss = train_model(model, optimizer, train_data_generator)\n",
    "        \n",
    "        val_accuracy = eval_model(model, val_data_generator)\n",
    "\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(train_loss))\n",
    "        print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Обучение\n",
    "\n",
    "Вся подготовка завершена, пора запускать обучение!\n",
    "\n",
    "Обычно после обучения в течение 30 эпох вы должны получить нейронную сеть, которая предсказывает метки с точностью более 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T10:09:18.807666Z",
     "iopub.status.busy": "2025-06-01T10:09:18.806977Z",
     "iopub.status.idle": "2025-06-01T10:43:54.158686Z",
     "shell.execute_reply": "2025-06-01T10:43:54.157892Z",
     "shell.execute_reply.started": "2025-06-01T10:09:18.807636Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:07<00:00, 23.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 30 took 69.081s\n",
      "  training loss (in-iteration): \t4.447209\n",
      "  validation accuracy: \t\t\t8.98 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:07<00:00, 23.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 of 30 took 69.105s\n",
      "  training loss (in-iteration): \t3.815926\n",
      "  validation accuracy: \t\t\t20.49 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:08<00:00, 22.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 of 30 took 69.903s\n",
      "  training loss (in-iteration): \t3.492629\n",
      "  validation accuracy: \t\t\t20.23 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:08<00:00, 22.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 of 30 took 70.092s\n",
      "  training loss (in-iteration): \t3.275819\n",
      "  validation accuracy: \t\t\t26.40 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:09<00:00, 22.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 of 30 took 70.429s\n",
      "  training loss (in-iteration): \t3.117984\n",
      "  validation accuracy: \t\t\t29.25 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:09<00:00, 22.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 of 30 took 70.418s\n",
      "  training loss (in-iteration): \t3.000135\n",
      "  validation accuracy: \t\t\t30.54 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:09<00:00, 22.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 of 30 took 70.301s\n",
      "  training loss (in-iteration): \t2.905329\n",
      "  validation accuracy: \t\t\t32.66 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:08<00:00, 22.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 of 30 took 70.022s\n",
      "  training loss (in-iteration): \t2.820575\n",
      "  validation accuracy: \t\t\t31.03 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:07<00:00, 22.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 of 30 took 69.259s\n",
      "  training loss (in-iteration): \t2.754103\n",
      "  validation accuracy: \t\t\t35.11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:08<00:00, 22.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 of 30 took 69.623s\n",
      "  training loss (in-iteration): \t2.690543\n",
      "  validation accuracy: \t\t\t34.11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:08<00:00, 22.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 of 30 took 69.280s\n",
      "  training loss (in-iteration): \t2.642986\n",
      "  validation accuracy: \t\t\t34.72 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:08<00:00, 22.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 of 30 took 69.745s\n",
      "  training loss (in-iteration): \t2.596892\n",
      "  validation accuracy: \t\t\t37.48 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:08<00:00, 22.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 of 30 took 69.368s\n",
      "  training loss (in-iteration): \t2.553897\n",
      "  validation accuracy: \t\t\t37.73 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:08<00:00, 22.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 of 30 took 69.548s\n",
      "  training loss (in-iteration): \t2.511193\n",
      "  validation accuracy: \t\t\t39.10 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:08<00:00, 22.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 of 30 took 69.820s\n",
      "  training loss (in-iteration): \t2.481038\n",
      "  validation accuracy: \t\t\t38.48 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:08<00:00, 22.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 of 30 took 69.553s\n",
      "  training loss (in-iteration): \t2.444488\n",
      "  validation accuracy: \t\t\t39.52 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:08<00:00, 22.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 of 30 took 69.643s\n",
      "  training loss (in-iteration): \t2.418893\n",
      "  validation accuracy: \t\t\t39.96 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:07<00:00, 23.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 of 30 took 69.002s\n",
      "  training loss (in-iteration): \t2.390404\n",
      "  validation accuracy: \t\t\t38.38 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:07<00:00, 23.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 of 30 took 68.945s\n",
      "  training loss (in-iteration): \t2.365738\n",
      "  validation accuracy: \t\t\t40.82 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:07<00:00, 23.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 of 30 took 68.887s\n",
      "  training loss (in-iteration): \t2.340218\n",
      "  validation accuracy: \t\t\t40.22 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:07<00:00, 23.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 of 30 took 69.189s\n",
      "  training loss (in-iteration): \t2.311767\n",
      "  validation accuracy: \t\t\t41.00 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:06<00:00, 23.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 of 30 took 67.346s\n",
      "  training loss (in-iteration): \t2.293052\n",
      "  validation accuracy: \t\t\t41.46 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:06<00:00, 23.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 of 30 took 67.501s\n",
      "  training loss (in-iteration): \t2.274967\n",
      "  validation accuracy: \t\t\t40.40 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:05<00:00, 23.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 of 30 took 67.148s\n",
      "  training loss (in-iteration): \t2.253732\n",
      "  validation accuracy: \t\t\t39.51 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:06<00:00, 23.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 of 30 took 67.422s\n",
      "  training loss (in-iteration): \t2.235507\n",
      "  validation accuracy: \t\t\t41.08 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:07<00:00, 23.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 of 30 took 68.465s\n",
      "  training loss (in-iteration): \t2.217658\n",
      "  validation accuracy: \t\t\t41.94 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:07<00:00, 23.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 of 30 took 69.028s\n",
      "  training loss (in-iteration): \t2.202840\n",
      "  validation accuracy: \t\t\t41.76 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:07<00:00, 23.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 of 30 took 69.044s\n",
      "  training loss (in-iteration): \t2.183850\n",
      "  validation accuracy: \t\t\t41.82 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:07<00:00, 23.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 of 30 took 69.044s\n",
      "  training loss (in-iteration): \t2.172432\n",
      "  validation accuracy: \t\t\t42.06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:07<00:00, 23.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 of 30 took 69.132s\n",
      "  training loss (in-iteration): \t2.156927\n",
      "  validation accuracy: \t\t\t41.80 %\n"
     ]
    }
   ],
   "source": [
    "train_loop(model, opt, train_batch_gen, val_batch_gen, num_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Say Hello to ResNets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части вам нужно переопределить вашу модель, все остальное останется прежним. Как и в случае с VGG, мы собираемся определить модель, подобную ResNet, а не классическую архитектуру, разработанную для классификации ImageNet.\n",
    "\n",
    "\"ResNet-подобный\" обычно означает, что ваша сеть состоит из \"residual блоков\". Существует два широко используемых типа блоков: с двумя и с тремя свертками:\n",
    "![resnet_blocks](https://miro.medium.com/max/613/1*zS2ChIMwAqC5DQbL5yD9iQ.png)\n",
    "\n",
    "На практике часто используются блоки с тремя свертками, поскольку они позволяют построить более глубокую сеть с меньшими параметрами. Блоки с двумя свертками обычно используются для сравнения с non-residual сетями, особенно с VGG и AlexNet.\n",
    "\n",
    "Вот таблица из статьи \"[Deep Residual Learning for Image Recognition]\"(https://arxiv.org/pdf/1512.03385.pdf), в которой описываются классические конфигурации сетей ResNet. Обычно их называют ResNet-18, ResNet-34 и так далее, используя количество слоев в качестве идентификатора. Обратите внимание, что сети, начиная с ResNet-50, основаны на 3-сверточных блоках. На самом деле ResNet-18 и ResNet-34 были представлены только для сравнения с VGG, в то время как ResNet-50 обычно используется на практике в качестве хорошего бейслайна.\n",
    "\n",
    "![изображение](https://miro.medium.com/max/2400/1*aq0q7gCvuNUqnMHh4cpnIw.png)\n",
    "\n",
    "Как и в случае с VGG, мы собираемся создать нашу собственную конфигурацию для сети. Давайте используем 2-сверточных блока для сравнения с vgg и возьмем сеть типа [Conv7x7 - 32] + [conv32-block, conv32-block] + [conv64-block, conv64-block] + [conv128-block, conv128-block] + [GlobalAveragePooling] + fc200 + softmax\n",
    "\n",
    "По сравнению с ResNet18, мы уменьшили количество фильтров и убрали max-pooling в начале и в последнем наборе сверток"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:05:55.796677Z",
     "iopub.status.busy": "2025-06-02T00:05:55.796127Z",
     "iopub.status.idle": "2025-06-02T00:05:55.804652Z",
     "shell.execute_reply": "2025-06-02T00:05:55.803816Z",
     "shell.execute_reply.started": "2025-06-02T00:05:55.796652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class ResNetBlock2(nn.Module):\n",
    "    \"\"\"\n",
    "    Module implements the following function:\n",
    "    \n",
    "    output = relu(F(input) + Residual(input)), where: \n",
    "        Residual(x) = Conv + bn + relu + conv + bn\n",
    "        F(x) = x                                        , if in_channels == out_channels and stride == 1\n",
    "             = Conv1x1(in_channel, out_channel, stride) , otherwise\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding='same'):\n",
    "        super().__init__()\n",
    "        # YOUR CODE: define conv1, bn1, relu1, conv2, bn2 for residual branch computation \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = None  # conv for main branch adopatation\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.conv3 = nn.Conv2d(in_channels, out_channels, 1, stride, padding=0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # YOUR CODE: compute residual branch, \n",
    "        # DON'T OVERRIDE 'x' as you will need it \n",
    "        \n",
    "        residual = self.conv1(x)\n",
    "        residual = self.bn1(residual)\n",
    "        residual = self.relu1(residual)\n",
    "        residual = self.conv2(residual)\n",
    "        residual = self.bn2(residual)\n",
    "\n",
    "        if self.conv3 is not None:\n",
    "            x = self.conv3(x)\n",
    "\n",
    "        result = self.relu2(residual + x)\n",
    "        return result\n",
    "\n",
    "def create_resnet_like_network():\n",
    "    model = nn.Sequential()\n",
    "    \n",
    "    config = [[32, 32], [64, 64], [128, 128]]\n",
    "    model.add_module('init_conv', ConvBNRelu(3, 32, kernel_size=7, stride=2, padding=3))\n",
    "    \n",
    "    in_channels = 32\n",
    "    for i in range(len(config)):\n",
    "        for j in range(len(config[i])):\n",
    "            out_channels = config[i][j]\n",
    "            stride = 2 if i != 0 and j == 0 else 1\n",
    "            # YOUR CODE: add ResNetBlock2 module to model\n",
    "            model.add_module(f\"resnet_{i}_{j}\", ResNetBlock2(in_channels, out_channels))\n",
    "            \n",
    "            in_channels = out_channels\n",
    "    model.add_module('pool', GlobalAveragePool((2,3)))\n",
    "    model.add_module('logits', nn.Linear(out_channels, 200))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда давайте потренируем нашу сеть. Обычно после обучения в течение 30 эпох вы должны получить нейронную сеть, которая предсказывает метки с точностью >40% и дает около +1% профита по сравнению с vgg, из предыдущего эксперимента."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T12:05:20.660422Z",
     "iopub.status.busy": "2025-06-01T12:05:20.659708Z",
     "iopub.status.idle": "2025-06-01T13:08:54.259448Z",
     "shell.execute_reply": "2025-06-01T13:08:54.258595Z",
     "shell.execute_reply.started": "2025-06-01T12:05:20.660399Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:55<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 30 took 119.022s\n",
      "  training loss (in-iteration): \t4.995792\n",
      "  validation accuracy: \t\t\t5.39 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:56<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 of 30 took 120.701s\n",
      "  training loss (in-iteration): \t4.448469\n",
      "  validation accuracy: \t\t\t10.20 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:00<00:00, 13.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 of 30 took 124.095s\n",
      "  training loss (in-iteration): \t4.073681\n",
      "  validation accuracy: \t\t\t16.63 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:02<00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 of 30 took 126.002s\n",
      "  training loss (in-iteration): \t3.805955\n",
      "  validation accuracy: \t\t\t19.67 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:02<00:00, 12.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 of 30 took 126.829s\n",
      "  training loss (in-iteration): \t3.597836\n",
      "  validation accuracy: \t\t\t22.03 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:03<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 of 30 took 127.236s\n",
      "  training loss (in-iteration): \t3.426312\n",
      "  validation accuracy: \t\t\t24.06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:03<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 of 30 took 126.952s\n",
      "  training loss (in-iteration): \t3.278197\n",
      "  validation accuracy: \t\t\t25.17 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:03<00:00, 12.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 of 30 took 127.482s\n",
      "  training loss (in-iteration): \t3.157911\n",
      "  validation accuracy: \t\t\t28.88 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:02<00:00, 12.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 of 30 took 126.735s\n",
      "  training loss (in-iteration): \t3.055842\n",
      "  validation accuracy: \t\t\t31.25 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:02<00:00, 12.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 of 30 took 126.681s\n",
      "  training loss (in-iteration): \t2.965494\n",
      "  validation accuracy: \t\t\t33.11 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:06<00:00, 12.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 of 30 took 130.028s\n",
      "  training loss (in-iteration): \t2.886883\n",
      "  validation accuracy: \t\t\t33.39 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:03<00:00, 12.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 of 30 took 127.728s\n",
      "  training loss (in-iteration): \t2.816399\n",
      "  validation accuracy: \t\t\t33.83 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:03<00:00, 12.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 of 30 took 127.364s\n",
      "  training loss (in-iteration): \t2.750823\n",
      "  validation accuracy: \t\t\t37.14 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:03<00:00, 12.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 of 30 took 127.087s\n",
      "  training loss (in-iteration): \t2.697510\n",
      "  validation accuracy: \t\t\t37.58 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:03<00:00, 12.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 of 30 took 127.104s\n",
      "  training loss (in-iteration): \t2.639844\n",
      "  validation accuracy: \t\t\t38.45 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:02<00:00, 12.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 of 30 took 126.747s\n",
      "  training loss (in-iteration): \t2.590533\n",
      "  validation accuracy: \t\t\t39.15 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:02<00:00, 12.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 of 30 took 126.711s\n",
      "  training loss (in-iteration): \t2.549003\n",
      "  validation accuracy: \t\t\t38.69 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:03<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 of 30 took 127.259s\n",
      "  training loss (in-iteration): \t2.504271\n",
      "  validation accuracy: \t\t\t40.84 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:03<00:00, 12.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 of 30 took 127.035s\n",
      "  training loss (in-iteration): \t2.463920\n",
      "  validation accuracy: \t\t\t40.66 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:03<00:00, 12.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 of 30 took 127.259s\n",
      "  training loss (in-iteration): \t2.423088\n",
      "  validation accuracy: \t\t\t40.98 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:03<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 of 30 took 127.005s\n",
      "  training loss (in-iteration): \t2.391640\n",
      "  validation accuracy: \t\t\t42.56 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:03<00:00, 12.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 of 30 took 127.225s\n",
      "  training loss (in-iteration): \t2.356455\n",
      "  validation accuracy: \t\t\t43.60 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:06<00:00, 12.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 of 30 took 130.243s\n",
      "  training loss (in-iteration): \t2.324929\n",
      "  validation accuracy: \t\t\t43.14 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:05<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 of 30 took 129.518s\n",
      "  training loss (in-iteration): \t2.298530\n",
      "  validation accuracy: \t\t\t42.53 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:05<00:00, 12.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 of 30 took 129.411s\n",
      "  training loss (in-iteration): \t2.275162\n",
      "  validation accuracy: \t\t\t43.99 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:05<00:00, 12.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 of 30 took 129.093s\n",
      "  training loss (in-iteration): \t2.241202\n",
      "  validation accuracy: \t\t\t43.95 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:04<00:00, 12.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 of 30 took 128.735s\n",
      "  training loss (in-iteration): \t2.221450\n",
      "  validation accuracy: \t\t\t44.95 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:04<00:00, 12.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 of 30 took 128.415s\n",
      "  training loss (in-iteration): \t2.196529\n",
      "  validation accuracy: \t\t\t45.41 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:04<00:00, 12.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 of 30 took 128.222s\n",
      "  training loss (in-iteration): \t2.174145\n",
      "  validation accuracy: \t\t\t44.83 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [02:05<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 of 30 took 129.647s\n",
      "  training loss (in-iteration): \t2.150678\n",
      "  validation accuracy: \t\t\t45.45 %\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE: create resnet model, move it to 'device', create same optimizer as in previous experiment\n",
    "model = create_resnet_like_network().to(device)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "train_loop(model, opt, train_batch_gen, val_batch_gen, num_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы внимательно изучали нашу сеть resnet, то могли заметить, что она имеет почти в 2 раза больше параметров и в 2 раза глубже, чем vgg. Давайте определим сеть, сопоставимую vgg, удвоив количество уровней conv.\n",
    "\n",
    "Наш новый сайт VGG-как архитектура будет [Сопу(16), усл. (16), MaxPool] + [Сопу(32), П(32), П(32), П(32), MaxPool] + [Сопу(64) отн(64) отн(64) отн(64), MaxPool] + [Сопу(128), Сопу(128), Сопу(128), Сопу(128)] + [GlobalAveragePooling] + [ФК(200) + softmax]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-02T00:06:08.337080Z",
     "iopub.status.busy": "2025-06-02T00:06:08.336805Z",
     "iopub.status.idle": "2025-06-02T00:42:41.271034Z",
     "shell.execute_reply": "2025-06-02T00:42:41.270213Z",
     "shell.execute_reply.started": "2025-06-02T00:06:08.337059Z"
    },
    "scrolled": true,
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:15<00:00, 20.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 30 took 76.990s\n",
      "  training loss (in-iteration): \t4.898927\n",
      "  validation accuracy: \t\t\t5.19 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:10<00:00, 22.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 of 30 took 71.997s\n",
      "  training loss (in-iteration): \t4.314600\n",
      "  validation accuracy: \t\t\t11.24 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:10<00:00, 22.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 of 30 took 72.341s\n",
      "  training loss (in-iteration): \t3.997217\n",
      "  validation accuracy: \t\t\t14.53 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:11<00:00, 21.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 of 30 took 72.664s\n",
      "  training loss (in-iteration): \t3.762672\n",
      "  validation accuracy: \t\t\t16.53 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:11<00:00, 21.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 of 30 took 73.504s\n",
      "  training loss (in-iteration): \t3.563827\n",
      "  validation accuracy: \t\t\t19.63 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:12<00:00, 21.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 of 30 took 74.098s\n",
      "  training loss (in-iteration): \t3.407187\n",
      "  validation accuracy: \t\t\t21.41 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:12<00:00, 21.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 of 30 took 74.471s\n",
      "  training loss (in-iteration): \t3.270753\n",
      "  validation accuracy: \t\t\t25.18 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:11<00:00, 21.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 of 30 took 72.717s\n",
      "  training loss (in-iteration): \t3.147905\n",
      "  validation accuracy: \t\t\t25.38 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:12<00:00, 21.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 of 30 took 74.108s\n",
      "  training loss (in-iteration): \t3.043375\n",
      "  validation accuracy: \t\t\t29.10 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:12<00:00, 21.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 of 30 took 73.650s\n",
      "  training loss (in-iteration): \t2.945174\n",
      "  validation accuracy: \t\t\t31.17 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:12<00:00, 21.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 of 30 took 73.713s\n",
      "  training loss (in-iteration): \t2.854758\n",
      "  validation accuracy: \t\t\t29.36 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:11<00:00, 21.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 of 30 took 73.030s\n",
      "  training loss (in-iteration): \t2.784204\n",
      "  validation accuracy: \t\t\t31.46 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:11<00:00, 21.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 of 30 took 73.154s\n",
      "  training loss (in-iteration): \t2.713158\n",
      "  validation accuracy: \t\t\t32.07 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:11<00:00, 21.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 of 30 took 72.719s\n",
      "  training loss (in-iteration): \t2.652459\n",
      "  validation accuracy: \t\t\t34.84 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:10<00:00, 22.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 of 30 took 72.341s\n",
      "  training loss (in-iteration): \t2.592696\n",
      "  validation accuracy: \t\t\t36.96 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:11<00:00, 21.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 of 30 took 72.647s\n",
      "  training loss (in-iteration): \t2.537666\n",
      "  validation accuracy: \t\t\t37.94 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:11<00:00, 21.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 of 30 took 72.974s\n",
      "  training loss (in-iteration): \t2.481836\n",
      "  validation accuracy: \t\t\t36.36 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:11<00:00, 21.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 of 30 took 72.843s\n",
      "  training loss (in-iteration): \t2.435808\n",
      "  validation accuracy: \t\t\t36.92 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:10<00:00, 22.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 of 30 took 72.182s\n",
      "  training loss (in-iteration): \t2.391074\n",
      "  validation accuracy: \t\t\t37.92 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:11<00:00, 22.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 of 30 took 72.589s\n",
      "  training loss (in-iteration): \t2.353432\n",
      "  validation accuracy: \t\t\t39.73 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:10<00:00, 22.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 of 30 took 72.437s\n",
      "  training loss (in-iteration): \t2.315925\n",
      "  validation accuracy: \t\t\t39.80 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:11<00:00, 22.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 of 30 took 72.579s\n",
      "  training loss (in-iteration): \t2.281543\n",
      "  validation accuracy: \t\t\t39.62 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:11<00:00, 21.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 of 30 took 72.707s\n",
      "  training loss (in-iteration): \t2.242086\n",
      "  validation accuracy: \t\t\t40.84 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:11<00:00, 21.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 of 30 took 72.941s\n",
      "  training loss (in-iteration): \t2.210207\n",
      "  validation accuracy: \t\t\t40.71 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:12<00:00, 21.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 of 30 took 73.762s\n",
      "  training loss (in-iteration): \t2.172421\n",
      "  validation accuracy: \t\t\t40.06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:11<00:00, 21.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 of 30 took 73.501s\n",
      "  training loss (in-iteration): \t2.146337\n",
      "  validation accuracy: \t\t\t41.99 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:11<00:00, 21.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 of 30 took 72.918s\n",
      "  training loss (in-iteration): \t2.119657\n",
      "  validation accuracy: \t\t\t42.01 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:10<00:00, 22.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 of 30 took 72.387s\n",
      "  training loss (in-iteration): \t2.082042\n",
      "  validation accuracy: \t\t\t42.06 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:10<00:00, 22.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 of 30 took 72.421s\n",
      "  training loss (in-iteration): \t2.064106\n",
      "  validation accuracy: \t\t\t42.05 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:10<00:00, 22.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 of 30 took 72.519s\n",
      "  training loss (in-iteration): \t2.034794\n",
      "  validation accuracy: \t\t\t41.66 %\n"
     ]
    }
   ],
   "source": [
    "model = create_vgg_like_network(config=[[16,16], [32,32,32,32], [64, 64, 64, 64], [128, 128, 128, 128]])\n",
    "model = model.to(device)\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "train_loop(model, opt, train_batch_gen, val_batch_gen, num_epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видите ли вы выгоду от residual связей? \n",
    "\n",
    "Качество сети vgg в этом эксперименте может быть даже хуже, чем качество сети vgg в первом эксперименте. Это связано с проблемой затухания градиента, которая затрудняет обучение глубоких нейронных сетей без residual связей."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "seminar_pytorch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "notebookId": "0bd81ca7-4175-4905-a84c-21ed8da72299"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
